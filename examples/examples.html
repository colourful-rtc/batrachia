<html>
    <html>
        <title>WebRTC Demo</title>
    </html>
    <body>
        <video autoplay controls style="
            background-color: #000;
            width: 100%;
            height: 100%;
            position: fixed;
            top: 0;
            left: 0;
        "></video>
    </body>
    <script>
        /**
         * Create a local media stream and provide it to the player as a media source. 
         * This media stream will store the audio and video tracks delivered by the 
         * remote end.
         */
        const stream = new MediaStream();
        document.querySelector('video').srcObject = stream;
        
        // Create a websocket connection to communicate with the signaling server.
        const socket = new WebSocket('ws://localhost');
        
        /**
         * Create a peer connection session, no configuration is used here, only 
         * sdp is specified to use the `unified-plan` scheme.
         */
        const pc = new RTCPeerConnection({
            sdpSemantics: 'unified-plan',
        });

        /**
         * Create a data channel, and then write the time of the current web page 
         * to the channel once every 2 seconds.
         */
        const channel = pc.createDataChannel('channel');
        setInterval(function() {
            /**
             * Before sending each time, check whether the status of the data 
             * channel is normally opened. If it is normally opened, 3 bytes of 
             * data are sent. These 3 bytes are the hour, minute, and second of 
             * the current time.
             */
            if (channel.readyState == 'open') {
                let buf = new Uint8Array(3);
                buf[0] = new Date().getHours();
                buf[1] = new Date().getMinutes();
                buf[2] = new Date().getSeconds();
                channel.send(buf);
            }
        }, 2000);

        /**
         * Handle the event that the remote end creates an audio and video track, 
         * and add the audio and video track created by the remote end to the 
         * local media stream.
         */
        pc.addEventListener('track', function({track}) {
            stream.addTrack(track, stream);
        });
        
        // Process the ice candidate generated by the current peer connection.
        pc.addEventListener('icecandidate', function({candidate}) {
            /**
             * Check whether the candidate is null, and check whether the websocket 
             * has been opened, and if the check is passed, send the ice candidate 
             * to the signaling server.
             */
            if (candidate && socket.readyState == 1) {
                socket.send(JSON.stringify({
                    kind: 'candidate',
                    sdpMLineIndex: candidate.sdpMLineIndex,
                    candidate: candidate.candidate,
                    sdpMid: candidate.sdpMid,
                }));
            }
        });
        
        // Process messages received by websocket.
        socket.addEventListener('message', async function({data}) {
            /**
             * The content of the message is of the type of json text, which is 
             * parsed into an object using json parser, and the kind of the 
             * message is extracted.
             */
            const {kind, ...payload} = JSON.parse(data);
            if (kind == 'answer') {
                /**
                 * After receiving the answer sent by the remote end, submit 
                 * the answer to the peer connection.
                 */
                await pc.setRemoteDescription({
                    type: 'answer',
                    sdp: payload.sdp,
                });
            } else if (kind == 'candidate') {
                /**
                 * The ice candidate received from the remote end is also 
                 * submitted to the peer connection.
                 */
                await pc.addIceCandidate({
                    sdpMLineIndex: payload.sdpMLineIndex,
                    candidate: payload.candidate,
                    sdpMid: payload.sdpMid,
                });
            }
        });

        /**
         * When the user clicks anywhere on the player, it is equivalent to 
         * starting a session.
         */
        document.querySelector('video').addEventListener('click', async function() {
            /**
             * Firstly, request to capture the desktop of the device where 
             * the current web page is located, requiring simultaneous 
             * capture of audio and video.
             */
            const captures = await navigator.mediaDevices.getDisplayMedia({
                audio: true,
                video: true,
            });

            // Add all captured media stream tracks to the peer connection.
            captures.getTracks().forEach(function(track) {
                pc.addTrack(track, captures);
            });

            /**
             * Create an offer and send it to the remote end through the 
             * signaling server.
             */
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            socket.send(JSON.stringify({
                kind: 'offer',
                sdp: offer.sdp
            }));
        });
    </script>
</html>
